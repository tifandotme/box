name: Backup ExcaliDash to GCS

on:
  schedule:
    - cron: "0 19 * * *" # Daily at 2AM Jakarta (19:00 UTC)
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      DOTENV_PRIVATE_KEY: ${{ secrets.DOTENV_PRIVATE_KEY }}

    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - uses: ./.github/actions/setup-infra
        with:
          oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}

      - uses: ./.github/actions/backup-setup

      - name: Perform Backup
        run: |
          SERVICE="excalidash"
          BUCKET_VAR="TF_VAR_${SERVICE}_bucket_name"

          GCS_BUCKET="gs://$(dotenvx get "$BUCKET_VAR" --env-file terraform/.env)"
          DATE=$(date +%Y%m%d-%H%M%S)
          DB_FILENAME="excalidash-db-${DATE}.sqlite"
          BACKUP_DIR="excalidash-db-backup"

          echo "=== Starting ExcaliDash Backup: $DATE ==="
          echo "Service: $SERVICE"
          echo "Bucket: $GCS_BUCKET"

          mkdir -p ./$BACKUP_DIR

          echo "Exporting database from API..."
          curl -s -f https://excalidash.tifan.me/api/export \
            -o ./$BACKUP_DIR/$DB_FILENAME

          if [ ! -f "./$BACKUP_DIR/$DB_FILENAME" ]; then
            echo "Failed to download database export"
            exit 1
          fi

          SIZE=$(ls -lh ./$BACKUP_DIR/$DB_FILENAME | awk '{print $5}')
          echo "Downloaded: $SIZE"

          echo "Uploading to GCS..."
          gsutil -m rsync -r -d ./$BACKUP_DIR "$GCS_BUCKET/$DATE"

          echo "âœ“ Backup completed: $GCS_BUCKET/$DATE"

      - name: Cleanup
        if: always()
        run: |
          rm -rf excalidash-db-backup
